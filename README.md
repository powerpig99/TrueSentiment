<!-- This is the markdown template for the final project of the Building AI course, 
created by Reaktor Innovations and University of Helsinki. 
Copy the template, paste it to your GitHub README and edit! -->

# TrueSentiment

Discover the truth and facts, as well as the sentiment against a topic.


## Summary

This project aims to use AI as a tool, to extend human capablities to digest information and discover the ground truth and facts about any topic, and in addition to analyze the general sentiment against it for better understanding of the public reactions. Therefore, the user can use it to upgrade his/her own operationg system, the HI (Human Intelligence), and make better decision in everyday life.


## Background

There are increasingly vast amount of information avaible to average person, which provides unprecidented access to knowledge and facts. Yet it is also a double edged sward and increased spreading of the misinformation and subject people to manipulation. 

Specifically:
* It is seemingly hard, and increasingly so, to tell the truth and facts from misinformation
* Even given the same information, seemingly intelligent and well intensioned "experts" can have completely oposit conclusions 
* Therefore, it is hard for people to make truely informed decisions, which have profund implications on their life, for instance to get the vaccine or not?


## How is it used?

It should be intuitively easy to use, for example, if I wanted to know if $TSLA worth investing, it should provide the following information:
* The key facts and conclusions about it, and the reliable sources for come up such conclusion
* The major misconceptions about it, the undelining driver and major proponents of them

In general, it should be used as a reference, just like a knowlegable aquantance, pointing the user to the right place to look and eventually come up with his/her own conclusion.

## Data sources and AI methods

Initially, the data would mainly come from Twitter, and it should be enough in most cases. While it is usually belived that more data is better for AI applications. In this case, the more important is to get high quality data. Imagine, that each and everyone user on Twitter is like a node (neuron) on a neurol network, with input from varioas information sources and tweets as outputs. If I wanted to know, say, the price movement of $TSLA, and there is one person who can always perfectly predict it. Then his tweets is the only date source we need here. In reality, of course, it is close to impossible to find such person, but we can try to find the best we can, then try to adding more sources only if it increases the accuracy of the intended result. This is pretty much how we human making everyday decisions.

The AI methods needed here are NLP tools, net-crowlers, CNNs, RNNs and Tranformers...not entirely sure at the moment but will figure out as we go.


## Challenges

It is not a one_stop shop, so people can mostly rely on it to make suggestions? Instead, the tool should help the user grow and continuesly upgrade the HI, Human Intelligence. Therefore, for difference people, the result will be different, and the user needs to be intellegent enought to take advantage of it.

It also challenging for the developer to ultimate make it and keep updating it.

## What next?

I will continue to learn AI development technologies and start building it out, first as a tool for myselfm but open for others to explore, then hipeful one day can be shared to general public. 


## Acknowledgments

* list here the sources of inspiration 
* do not use code, images, data etc. from others without permission
* when you have permission to use other people's materials, always mention the original creator and the open source / Creative Commons licence they've used
  <br>For example: [Sleeping Cat on Her Back by Umberto Salvagnin](https://commons.wikimedia.org/wiki/File:Sleeping_cat_on_her_back.jpg#filelinks) / [CC BY 2.0](https://creativecommons.org/licenses/by/2.0)
* etc
